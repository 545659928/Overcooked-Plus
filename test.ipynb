{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "import pygame\n",
    "\n",
    "from overcookedPlus.utils.utils import key2action\n",
    "from overcookedPlus.env_creater import create_env\n",
    "\n",
    "env = create_env(preset=\"easy\", n_agent=1, GUI=False, obs_mode=\"vector\")\n",
    "env.reset()\n",
    "done = False\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 61.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 589      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 110         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 555         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011501589 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.00414     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 70.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013990704 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.0421      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 178         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013531191 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 450         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 233         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011762824 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 9.37e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 599         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | 251        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 544        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01243631 |\n",
      "|    clip_fraction        | 0.0418     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.00056    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 451        |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.00683   |\n",
      "|    value_loss           | 1.27e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | 283        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 544        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00867521 |\n",
      "|    clip_fraction        | 0.0537     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.00027    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 609        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00672   |\n",
      "|    value_loss           | 1.27e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 295          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046760943 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 5.82e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 762          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 330          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131405275 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 4.83e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 584          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 356         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010995359 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.000125    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 413         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015664801 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 5.84e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    value_loss           | 2.04e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 445          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062062247 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 1.04e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 491          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014583392 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 1.01e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000688    |\n",
      "|    value_loss           | 3.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 519         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016712107 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 3.93e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 514         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009332027 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 7.39e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 539         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 541         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007994549 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | -2.25e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    value_loss           | 2.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 566         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000785197 |\n",
      "|    clip_fraction        | 0.00142     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | -4.77e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00059    |\n",
      "|    value_loss           | 2.95e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 574          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002455988 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.865       |\n",
      "|    explained_variance   | 3.99e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000225    |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 571          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019327041 |\n",
      "|    clip_fraction        | 0.0509       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.822       |\n",
      "|    explained_variance   | 1.49e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | 0.00243      |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 583          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020685128 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.79        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 2.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 586          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011791631 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.75        |\n",
      "|    explained_variance   | -5.96e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000377    |\n",
      "|    value_loss           | 3.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 579          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068079387 |\n",
      "|    clip_fraction        | 0.0567       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.735       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 581          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020183162 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.746       |\n",
      "|    explained_variance   | 8.94e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | 0.0013       |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 200       |\n",
      "|    ep_rew_mean          | 591       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 540       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0057073 |\n",
      "|    clip_fraction        | 0.00303   |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.727    |\n",
      "|    explained_variance   | 1.19e-06  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.41e+03  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -0.00153  |\n",
      "|    value_loss           | 3.21e+03  |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 605           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 541           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 94            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042207818 |\n",
      "|    clip_fraction        | 0.0279        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.7          |\n",
      "|    explained_variance   | 1.13e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.59e+03      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.0005       |\n",
      "|    value_loss           | 3.17e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 631          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037165326 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.637       |\n",
      "|    explained_variance   | -5.96e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 3.38e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 628         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 541         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001392799 |\n",
      "|    clip_fraction        | 0.00083     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 2.15e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05e+03    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 4.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 627         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004747795 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 4.77e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    value_loss           | 2.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 649          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013014034 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 2.98e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000883    |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 625          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018517247 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.652       |\n",
      "|    explained_variance   | 1.85e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 0.00127      |\n",
      "|    value_loss           | 3.42e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 655         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005771136 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 4.17e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    value_loss           | 3.43e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 655           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 548           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 119           |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021652982 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.606        |\n",
      "|    explained_variance   | -0.085        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.45e+03      |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.000225     |\n",
      "|    value_loss           | 3.33e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 658           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 550           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 122           |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039740762 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.585        |\n",
      "|    explained_variance   | 0.0116        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+03      |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.000398     |\n",
      "|    value_loss           | 3.6e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 672           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 552           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 126           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033938387 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.604        |\n",
      "|    explained_variance   | 0.0359        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.99e+03      |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.00027      |\n",
      "|    value_loss           | 3.61e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014745115 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.587       |\n",
      "|    explained_variance   | 0.0653       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.14e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00054     |\n",
      "|    value_loss           | 3.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 553          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012821222 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.000755    |\n",
      "|    value_loss           | 3.89e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 704           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 555           |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038097697 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.549        |\n",
      "|    explained_variance   | 0.141         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.12e+03      |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.000303     |\n",
      "|    value_loss           | 3.51e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 692          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 556          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010140754 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.079        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.000774    |\n",
      "|    value_loss           | 3.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 674          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 556          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006505912 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.00833      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000683    |\n",
      "|    value_loss           | 3.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 699          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 557          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017887951 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 641           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 558           |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 83968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027111982 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.181         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.26e+03      |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -0.000312     |\n",
      "|    value_loss           | 3.95e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 641         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001672532 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.0681      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 672           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 558           |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 157           |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3679062e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.423        |\n",
      "|    explained_variance   | 0.22          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.43e+03      |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -2.89e-05     |\n",
      "|    value_loss           | 4.08e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 663          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 559          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026598736 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91e+03     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 5.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 659          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.456358e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.366       |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.000124    |\n",
      "|    value_loss           | 4.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | 662         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002250891 |\n",
      "|    clip_fraction        | 0.0022      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.000955   |\n",
      "|    value_loss           | 4.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | 668          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 563          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015890703 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.306       |\n",
      "|    explained_variance   | -0.0429      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.19e+03     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000964    |\n",
      "|    value_loss           | 5.49e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 664           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 565           |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 173           |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015115348 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.282        |\n",
      "|    explained_variance   | 0.196         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.61e+03      |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000103     |\n",
      "|    value_loss           | 4.02e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | 690           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 566           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 177           |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062732265 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.259        |\n",
      "|    explained_variance   | 0.304         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.52e+03      |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000571     |\n",
      "|    value_loss           | 3.81e+03      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1c6fe73b2e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_env(preset=\"easy\", n_agent=1, GUI=True, obs_mode=\"vector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for i in range(100):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs=env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while not done:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            done = True\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            key = pygame.key.name(event.key)\n",
    "            print(f\"Key: {key}\")\n",
    "            action = key2action(key)\n",
    "            if action is not None:\n",
    "                new_obs, reward, done, info = env.step([action])\n",
    "                print(f\"Reward: {reward}, Done: {done}, Info: {info}\")\n",
    "                obs = new_obs\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        ...,\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        ...,\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        ...,\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        ...,\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        ...,\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        ...,\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51]]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "import pygame\n",
    "\n",
    "from overcookedPlus.utils.utils import key2action\n",
    "from overcookedPlus.env_creater import create_env\n",
    "\n",
    "env = create_env(preset=\"easy\", n_agent=1, GUI=False, obs_mode=\"vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "obs=env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 1.0, (27,), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# \n",
    "plt.imshow(obs)\n",
    "plt.axis('off')  # \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.14)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from overcookedPlus.env_creater import create_env\n",
    "from overcookedPlus.utils.utils import key2action\n",
    "\n",
    "env = create_env(preset=\"hard\", n_agent=1, GUI=True)\n",
    "\n",
    "done = False\n",
    "obs = env.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: left alt\n",
      "Key: s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\pureb\\anaconda3\\envs\\GA\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: 10, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: 9.9, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -2.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: w\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [3], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: a\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [2], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: s\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [1], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n",
      "Key: d\n",
      "Reward: -0.1, Done: False, Info: {'cur_mac': [0], 'mac_done': [True]}\n"
     ]
    }
   ],
   "source": [
    "done=False\n",
    "while not done:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            done = True\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            key = pygame.key.name(event.key)\n",
    "            print(f\"Key: {key}\")\n",
    "            action = key2action(key)\n",
    "            if action is not None:\n",
    "                new_obs, reward, done, info = env.step([action])\n",
    "                print(f\"Reward: {reward}, Done: {done}, Info: {info}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        ...,\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        ...,\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        ...,\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        ...,\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        ...,\n",
       "        [220, 170, 110],\n",
       "        [220, 170, 110],\n",
       "        [114,  93,  51]],\n",
       "\n",
       "       [[114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        ...,\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51],\n",
       "        [114,  93,  51]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.preceptionManager.oneHotTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ingredients': ('onion',),\n",
       "  'task_encoding': [0, 0, 1, 0],\n",
       "  'task_start_time': 0,\n",
       "  'task_end_time': 0},\n",
       " {'ingredients': ('tomato', 'lettuce'),\n",
       "  'task_encoding': [1, 1, 0, 0],\n",
       "  'task_start_time': 35,\n",
       "  'task_end_time': 0}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.taskManager.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pygame.quit()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Reward Curve\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Reward\")\n",
    "for agent in env.agent:\n",
    "    plt.plot(agent.reward, label=f\"Agent {agent.color}\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
